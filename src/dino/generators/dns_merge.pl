#!/usr/bin/perl -w

# ------------------------------------------------------
# build_dns
# 
# A script which builds and verifies DNS files from two 
# sources: a computer generated file, and a hand-edited
# file. Some simple integrity checking of file output 
# can also be performed.              -- 2007-02-01 Marc Slayton

use strict;
use Getopt::Long;

my ($opt_d, $opt_h, $opt_c, $opt_g, $opt_e, $opt_l, $opt_x);

$opt_l = '/var/log/dns';

GetOptions(
  "d"         => \$opt_d, "debug"           => \$opt_d,
  "h"         => \$opt_h, "help"            => \$opt_h,
  "c"         => \$opt_c, "check"           => \$opt_c,
  "g=s"       => \$opt_g, "generated=s"     => \$opt_g,
  "e=s"       => \$opt_e, "edited=s"        => \$opt_e,
  "x=s"       => \$opt_x, "xtra=s"          => \$opt_x,
  "l=s"       => \$opt_l, "log-dir=s"       => \$opt_l,
) || usage();

usage() if $opt_h;

my $debug = $opt_d;
my $checking = $opt_c;
my $log_dir = $opt_l;
my $date = `date`;
chomp($date);

print "DBG> path to generated file: $opt_g\n" if ($debug);
print "DBG> path to edited file: $opt_e\n" if ($debug);

# Function: usage
sub usage 
{
  die <<'EOT';

  build_dns 
  ---------
  Builds MW internal DNS config from a generated file and an 
  edited file.  Requires both files on the command line.
  Also does some integrity checking with the -c flag.

  usage: build_tinydns -g <generated_file> -e <edited_file> -x <xtra_file> [-c] [-d] [-h] 
   
  -d    : Enable debugging mode.
  -h    : (This) Help message.
  -c    : Perform some integrity checking while building the DNS file.
  -g    : Path to generated DNS file.
  -e    : Path to hand edited DNS file.
  -x    : Path to xtra DNS file. 

EOT

  exit 1;
} # usage


# need both generated and edited flags
usage() if ( ! (( $opt_g ) && ( $opt_e )) ) ;

my ($crit, $warn);

# load generated entries
open (G, "$opt_g") 
  or die "ERROR: Unable to open $opt_g: $!\n";
         
my %g;

while (<G>)
{
  chomp;
  s/^\s+//; s/\s+$//; s/#.*//;
  next unless $_;
  print "DBG> g: parsed line: $_\n" if ($debug);

  # only A records, CNAMEs, and forward-reverses.
  if ( ! /^[\=\+]/ ) 
  { 
    print STDERR "ERROR: bad line in gfile: $_\n";
    $crit++;    
    next;
  } 

  my ($k, $v) = split(/:/, $_);
  $g{$k} = $v;
  print "DBG> parsed: \|$k\|, \|$g{$k}\|\n" if( $debug );

}   
    
close G;


# load edited entries        
open (E, "$opt_e") 
  or die "ERROR: Unable to open $opt_e: $!\n";
         
my( %e, %e_fw, %e_frev, %e_cn, %e_wc, @e_misc );

while (<E>)
{
  chomp;
  s/^\s+//; s/\s+$//; s/#.*//;
  next unless $_;
  print "DBG> e: parsed line: $_\n" if( $debug );

  # collect zone, MX, and PTR records separately.
  if ( s/^([\.\@\^\&].*:.*:[^:]+)/$1/ ) 
  {
    push @e_misc, $_;
    next;
  }

  # reject CNAMEs or malformed lines
  if ( ! /^[\=\+C\*]/ ) 
  { 
    print STDERR "ERROR: bad line in efile: $_\n";
    $crit++;
    next;
  } 

  my ($k, $v) = split(/:/, $_);
  # load array for name comparisons.
  if ( $k =~ s/^[\=]// ) 
  {
    $e_frev{$k} = $v;
  } 
  elsif ( $k =~ s/^[\+]// )
  {
    $e_fw{$k} = $v;
  }
  elsif ( $k =~ s/^[C]// )
  {
    $e_cn{$k} = $v;
  }
  elsif ( $k =~ s/^[\*]// )
  {
    $e_wc{$k} = $v;
  }
  else
  {
    print STDERR "Unknown record type found while loading check arrays.\n";
  }
  # combined hash, for name deduping.
  %e = ( %e_fw, %e_frev, %e_cn, %e_wc );

  print "DBG> parsed: \|$k\|, \|$e{$k}\|\n" if( $debug );
}   
    
close E;

# always check
$checking = 1;

if ( $checking ) 
{
  &make_dir;

  my $eref = \%e;
  my $gref = \%g;

  &check_edited($eref);
  &check_generated($gref);
}

# abort if critical errors found.
if ( $crit ) 
{ 
  print STDERR "cannot produce config: $crit critical errors found.\n"; 
  exit 1;
}  

# print header
print STDOUT <<EOH;
###  WARNING-WARNING-WARNING-WARNING-WARNING
###-------------------------------------------
###       DO NOT EDIT THIS FILE.  
### It is automatically generated by build_dns.
###-------------------------------------------
### Last build date: $date 
### Hand Edited section follows... 
### 
EOH

# print edited file to stdout
open (E, "$opt_e") 
  or die "ERROR: Unable to open $opt_e: $!\n";

while (<E>) 
{
  print;
}

print "\n\n\n###\n### X-tra DNS external section follows...\n###\n";

# print x-tra file to stdout
open (X, "$opt_x") 
  or die "ERROR: Unable to open $opt_x: $!\n";

while (<X>) 
{
  print;
}

print "\n\n\n###\n### Auto-generated section follows...\n###\n";

# print generated values.
foreach my $k (sort keys %g)
{
  print STDOUT "$k:$g{$k}\n"
}

print STDOUT "### EOF\n";


# Integrity checks for the generated file.
sub check_generated
{
  my $r = shift;
  my %hr = reverse %$r;

  # initiate logging.
  #
  # NOTE: we keep messages from the most recent run 
  # in a separate file, for easy harvesting.
 
  my $gm = "$log_dir/generated.msg";
  my $gl = "$log_dir/generated.log";

  # save old msgs to log.
  if( -f "$gm" ) 
  {
    open( GL, ">> $gl" ) 
      or die "could not open $gl: $!\n";
    open( GM, "cat $gm |" )
      or die "could not open $gm: $!\n";

    while (<GM>) { print GL $_; }

    close(GM);
    close(GL);
  }

  # create new msgs.
  open( GM, "> $log_dir/generated.msg")
    or die "could not open file: $!\n";
  
  # NOTE: MX, CNAME, and zone records are silently 
  # discarded from the generated file at load time.  
  # (so are unpaired A or PTR records.)

  # entries must be 5-dot names.
  foreach my $k ( sort keys %$r )  
  {
    if( $k !~ /^[\=\+]\S+\.\S+\.\S+\.metaweb\.com/ )
    {
      g_out( "host: $k does not follow 4-dot notation. Removing..." );
      delete $r->{$k};
      $warn++;
    }
  }
 
  # remove entries with illegal characters.
  foreach my $k ( sort keys %$r ) 
  {
    if( $k =~ /[\s]/ ) 
    {
      g_out( "host: $k contains illegal characters. Removing..." );
      delete $r->{$k};
      $warn++;
    }
  }

  # only private IPs in generated records.
  my @ip_inval = grep { $_ !~ /^(172|192|10|127)\./ } sort keys %hr ;
  if( $#ip_inval >= 0 ) 
  {
    my $invalid = $#ip_inval;
    $invalid++;
    g_out( "$invalid records found without an internal IP. Removing..." );
    foreach my $i ( @ip_inval )
    {
      my $n = $hr{$i};
      g_out( "deleting $n:$i ..." );
      delete $r->{$n};
      $warn++;
    }
  }

  # IPs should be unique in the generated file.
  #
  # NOTE: failing this test aborts the DNS build, 
  # since the program cannot decide which of the IP 
  # duplicates is supposed to exist. The user must 
  # try again in this case.
  
  # hash of repeats, i.e. 'ip' => 'counter++'
  #
  # TODO: 
  # 1) create slices for '=' and '+'
  # 2) No duplicates in '='
  # 3) No duplicate NAMES in all. (remember: ipmi-)
  my %h = ();
  %h = map { $_ => $h{$_}++ } sort keys %hr;
  # list of ips with counter > 1
  my @ip_dup = grep { $h{$_} > 1 } sort keys %h ;

  if( $#ip_dup >= 0 )
  {
    my $dupes = $#ip_dup;
    $dupes++;
    g_out( "FATAL: $dupes duplicate ips were found in the generated file." );
    foreach my $i ( @ip_dup ) 
    {
      g_out( "ip: $_" );
      $crit++;
    }
    g_out( "ADMIN MUST FIX.");
  } 

  # no names shared between generated and edited file.
  my @name_dup = grep { defined $e{$_} } sort keys %$r; 
  if( $#name_dup >= 0 )
  {
    my $dupes = $#name_dup ; 
    $dupes++;
    g_out( "$dupes names were found to be duplicates of names in the ");
    g_out( "hand-edited file. Removing these from the generated file..." );
    foreach my $n ( @name_dup )
    {
      g_out( "deleting $r->{$n} ..." );
      delete $r->{$n};
      $warn++;
    }
  }

  # eliminate forward/reverse ips already contained in the 
  # edited file.
  my %er = ();
  %er = reverse %e_frev;
  my @cross_dup = grep { defined $er{$_} } sort keys %hr;
  if( $#cross_dup >= 0 ) 
  {
    my $dupes = $#cross_dup;
    $dupes++;
    g_out( "$dupes ips found already to be defined in forward/reverse pairs ");
    g_out( "from the edited file. Deleting the generated entries...");
    foreach my $ip ( @cross_dup )
    {
      my $n; 
      $n = $hr{$ip};
      g_out( "deleting entry: $n:$ip..."); 
      delete $r->{$n} ;
    }
  } #/ end if
  close(GM); 
} #/ end check_generated

# integrity checks for the hand-edited file.
# since the file can be hand-edited, we only 
# warn about these.
sub check_edited
{
  my $r = shift;
  # inverted hash
  my %hr = reverse %$r;
 
  # initiate logging.
  #
  # NOTE: we keep messages from the most recent run 
  # in a separate file, for easy harvesting.
 
  my $em = "$log_dir/edited.msg";
  my $el = "$log_dir/edited.log";

  # save old msgs to log.
  if( -f "$em" ) 
  {
    open( EL, ">> $el" ) 
      or die "could not open $el: $!\n";
    open( EM, "cat $em |" )
      or die "count not open $em: $!\n";

    while (<EM>) { print EL $_; }

    close(EM);
    close(EL);
  }

  # create new msgs.
  open( EM, "> $log_dir/edited.msg")
    or die "could not open file: $!\n";
  
  # warn about entries with illegal characters.
  foreach my $k ( sort keys %$r ) 
  {
    if( $k =~ /[\s]/ ) 
    {
      e_out( "host: $k contains illegal characters.");
      $warn++;
    }
  }

  # warn about invalid IPs 
  my @ip_invalid = grep { $_ =~ /^0(\d*)?\./ } sort keys %hr ;
  if( $#ip_invalid >= 0 ) 
  {
    my $invalid = $#ip_invalid;
    $invalid++;
    e_out( "$invalid records found without a valid IP." );
    foreach my $i ( @ip_invalid )
    {
      e_out( "invalid ip: $hr{$i}:$i ..." );
      $warn++;
    }
  }

  # IPs should be unique among the forward/reverse entries
  #
  # NOTE: failing this test aborts the DNS build, 
  # since the program cannot decide which of the IP 
  # duplicates is supposed to exist. The user must 
  # try again in this case.
  
  # tally the ips 
  my( %er, %h );
  %er = reverse %e_frev;
  %h = map { $_ => $h{$_}++ } sort keys %er ;
  # select those that occur more than once.
  my @ip_dup = grep { $h{$_} > 1 } sort keys %h ;

  if( $#ip_dup >= 0 )
  {
    my $dupes = $#ip_dup;
    $dupes++;
    e_out( "FATAL: $dupes duplicate reverses were found in the edited file." );
    e_out( "ADMIN MUST FIX." );
    foreach my $ip ( @ip_dup ) 
    {
      my $n = $er{$ip};
      e_out( "duplicate: $n:$ip" );
      $crit++;
    }
  } 
  # reset
  @ip_dup = ();

  # final check: uniques among zones and MXes
  my %u = ();
  %u = map { $_ => $u{$_}++ } @e_misc ;
  my @misc_dup = grep { $u{$_} > 1 } sort keys %u;

  if( $#misc_dup >= 0 )
  {
    my $dupes = $#misc_dup;
    $dupes++;
    e_out( "WARNING: $dupes duplicate zone or MX entries were discovered. You should remove these." );
    foreach my $d ( @misc_dup )
    {
      e_out( "dupe: $d\n" );
      $warn++;
    }  
  } 
  close(EM);
}

# print routines 
# (which tee output)
sub g_out
{
  print STDERR "@_\n";
  print GM "$date: @_\n";
}

sub e_out
{
  print STDERR "@_\n";
  print EM "$date: @_\n";
}

# system call
sub make_dir
{
  my $cmd = "mkdir -p $log_dir";
  if( system( $cmd ) == 0 )
  {
    print "DBG> mkdir command successful.\n" if ( $debug );
  }
    else
  {
    my $err = $? >> 8;
    print "error while creating log dir: $err: $!\n";
  }
}

